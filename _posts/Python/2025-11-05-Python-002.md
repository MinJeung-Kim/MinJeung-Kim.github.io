---
layout: post
date: 2025-11-05
catalogue: "Python"
subject: "Python"
title: "Runpod ì¸ìŠ¤í„´ìŠ¤ë¡œ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±í•˜ê¸°"
subtitle: "ê·¸ë†ˆì˜ RunpodğŸ˜‘"
author: roxie
permalink: /Python/2
tags: [Python, FastAPI, Runpod, LLM, EEVE, AI]
---


# Runpod ì‚¬ìš© ê°œìš”
 
 Runpodì— ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ EEVE ëª¨ë¸ì„ ëŒë ¤ë³´ëŠ” ì‹¤ìŠµì„ ì§„í–‰í–ˆë‹¤.
 ì›¹ ê°œë°œìì¸ ë‚˜ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ Reactì™€ FastAPIë¡œ ë¡œì§ì„ êµ¬ì„±í•˜ê³ , Runpodì— ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ë©´ ë˜ê² ë‹¤ê³  ìƒê°í–ˆë‹¤,

#### ê·¸ëŸ¬ë‚˜ â— 

Runpod ìì²´ì—ì„œ í…ŒìŠ¤íŠ¸ í•´ë³¼ ìˆ˜ ìˆì„ë¿, ì—°ê²°ë˜ì§€ ì•Šì•˜ë‹¤.
ë‹¤ë¥¸ ìˆ˜ê°•ìƒë“¤ì€ Runpodì— EEVE ëª¨ë¸ì„ êµ¬ë™ì‹œì¼œ ë†“ì€ í›„, ëª¨ë¸ì„ jupyterë¡œ importí•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í–ˆì„ ë¿... ì•„ë¬´ë„ FastAPIì™€ ì—°ë™í•˜ëŠ” ë°©ë²•ì„ ëª¨ë¥¸ë‹¤ê³  í–ˆë‹¤.
ì•„ë¬´ë„ ëª¨ë¥´ëŠ”ê²ƒì„ ë˜ ì°¾ì•„ì„œ í•´ë‚´ëŠ” ê²ƒì´ ê°œë°œì˜ ê¸°ì¨ì¸ ë‚˜ì—ê²Œ ìƒˆë²½ê¹Œì§€ ì°¾ì•„ì„œ êµ¬í˜„í•´ë‚¼ ë™ê¸°ê°€ ìƒê²¼ë‹¤.


#### ê·¸ë˜ì„œ â“

ìš°ì„  Runpodê³¼ ollamaì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.

<br />

## ğŸ“º Runpod ì´ë€?
RunpodëŠ” GPU í´ë¼ìš°ë“œ ì»´í“¨íŒ… í”Œë«í¼ìœ¼ë¡œ, AI/ML ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ì €ë ´í•˜ê³  ìœ ì—°í•œ GPU ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì œê³µí•œë‹¤.

### ì£¼ìš” íŠ¹ì§•
**1. GPU í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤**
   - NVIDIA GPU (A100, H100, RTX 4090 ë“±)ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ëŒ€ì—¬
   - AWS, GCPë³´ë‹¤ í›¨ì”¬ ì €ë ´í•œ ê°€ê²©
   - ì˜¨ë””ë§¨ë“œ(On-Demand) ë° ìŠ¤íŒŸ(Spot) ì¸ìŠ¤í„´ìŠ¤ ì œê³µ

**2. ì£¼ìš” ê¸°ëŠ¥**
   - Serverless GPU: APIë¥¼ í†µí•œ ìë™ ìŠ¤ì¼€ì¼ë§
   - Pod ë°°í¬: ì§€ì†ì ì¸ GPU ì¸ìŠ¤í„´ìŠ¤
   - í…œí”Œë¦¿: PyTorch, TensorFlow ë“± ì‚¬ì „ êµ¬ì„±ëœ í™˜ê²½
   - ë³¼ë¥¨ ìŠ¤í† ë¦¬ì§€: ë°ì´í„° ì˜êµ¬ ì €ì¥

**3. ì‚¬ìš© ì‚¬ë¡€**
   - ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
   - AI ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ìƒì„± (Stable Diffusion ë“±)
   - LLM íŒŒì¸íŠœë‹ ë° ì¶”ë¡ 
   - ë Œë”ë§ ì‘ì—…
   - ë°ì´í„° ë¶„ì„

**4. ì¥ì **
   - ë¹„ìš© íš¨ìœ¨ì  (AWS ëŒ€ë¹„ 70-80% ì €ë ´)
   - ë¹ ë¥¸ ë°°í¬ (ëª‡ ì´ˆ ë§Œì— ì‹œì‘)
   - ìœ ì—°í•œ ê³¼ê¸ˆ (ì´ˆ ë‹¨ìœ„ ì²­êµ¬)
   - ì»¤ë®¤ë‹ˆí‹° GPU ì œê³µ (ë” ì €ë ´)

**5. ê°€ê²© êµ¬ì¡°**
   - Secure Cloud: ë°ì´í„°ì„¼í„° GPU (ì•ˆì •ì , ë¹„ìŒˆ)
   - Community Cloud: ê°œì¸ ì œê³µ GPU (ì €ë ´, ì¤‘ë‹¨ ê°€ëŠ¥)
   - ì‹œê°„ë‹¹ $0.2 ~ $4+ (GPU ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)

<br />

## ğŸ¦™ Ollama ë€?
OllamaëŠ” ë¡œì»¬ í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ì´ë‹¤.

### ì£¼ìš” íŠ¹ì§•
**1. ë¡œì»¬ LLM ì‹¤í–‰ í”Œë«í¼**

   - ì¸í„°ë„· ì—°ê²° ì—†ì´ LLMì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰
   - Dockerì™€ ìœ ì‚¬í•œ ê°„ë‹¨í•œ CLI ì¸í„°í˜ì´ìŠ¤
   - macOS, Linux, Windows ì§€ì›

**2. ì§€ì› ëª¨ë¸**
   - Llama 3.1, 3.2 (Meta)
   - Mistral, Mixtral (Mistral AI)
   - Gemma (Google)
   - Phi-3 (Microsoft)
   - Qwen (Alibaba)
   - CodeLlama (ì½”ë“œ ìƒì„±)
   - ê¸°íƒ€ 100+ ëª¨ë¸

**3. ì£¼ìš” ëª…ë ¹ì–´**
```bash
  # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰
  ollama run llama3.2

  # ëª¨ë¸ ëª©ë¡ í™•ì¸
  ollama list

  # ëª¨ë¸ ë‹¤ìš´ë¡œë“œë§Œ
  ollama pull mistral

  # ëª¨ë¸ ì‚­ì œ
  ollama rm llama3.2

  # ì„œë²„ ì‹¤í–‰
  ollama serve
```

**4. API ì‚¬ìš©**
```bash
# REST APIë¡œ í˜¸ì¶œ
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "Why is the sky blue?"
}'
```

```python
# Pythonì—ì„œ ì‚¬ìš©
import requests

response = requests.post('http://localhost:11434/api/generate',
    json={
        'model': 'llama3.2',
        'prompt': 'Explain quantum computing'
    })
```

**5. ì¥ì **
   - í”„ë¼ì´ë²„ì‹œ: ë°ì´í„°ê°€ ì™¸ë¶€ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŒ
   - ë¹„ìš© ì ˆê°: API ë¹„ìš© ì—†ìŒ
   - ì˜¤í”„ë¼ì¸ ì‚¬ìš©: ì¸í„°ë„· ë¶ˆí•„ìš”
   - ì»¤ìŠ¤í„°ë§ˆì´ì§•: ëª¨ë¸ íŒŒì¸íŠœë‹ ê°€ëŠ¥
   - ë¹ ë¥¸ ì„¤ì¹˜: í•œ ì¤„ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜

**6. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**
   - ìµœì†Œ: 8GB RAM
   - ê¶Œì¥: 16GB+ RAM
   - GPU: ì„ íƒì‚¬í•­ (NVIDIA, AMD, Apple Silicon)
   - ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ë‹¤ë¦„ (7B ëª¨ë¸ ~4GB, 70B ëª¨ë¸ ~40GB)

**7. ì‚¬ìš© ì‚¬ë¡€**
   - ë¡œì»¬ ì±—ë´‡ ê°œë°œ
   - ì½”ë“œ ìƒì„± ë° ë¦¬ë·°
   - í…ìŠ¤íŠ¸ ìš”ì•½ ë° ë²ˆì—­
   - RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ
   - í”„ë¡œí† íƒ€ì´í•‘ ë° ì‹¤í—˜

<br />

# Runpod Endpoint ìƒì„±í•˜ê¸°
Runpodì˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ëª©ì ì— ëŒ€í•´ ëª…í™•íˆ í•˜ê¸° ìœ„í•´ ê¸°íš í”Œë¡œìš° ì‘ì„±ê³¼ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ê¸°íš í–ˆë‹¤.

**êµ¬ì„± ëª©í‘œ**

- ğŸ§  EEVE í•œêµ­ì–´ LLM ëª¨ë¸ì„ RunPod GPU ì¸ìŠ¤í„´ìŠ¤ì— ì˜¬ë¦¼
- âš™ï¸ FastAPI ë°±ì—”ë“œì—ì„œ RunPod ì¸ìŠ¤í„´ìŠ¤ì˜ ëª¨ë¸ì„ API í˜•íƒœë¡œ í˜¸ì¶œ
- ğŸ’¬ React í”„ë¡ íŠ¸ì—”ë“œ â†’ FastAPI â†’ RunPod(EEVE) êµ¬ì¡°ë¡œ ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰

**êµ¬ì„± íë¦„**

```
[React Frontend]
     â†“ (REST call)
[FastAPI Backend]
     â†“ (requests.post)
[RunPod GPU Instance]
     â†‘
[EEVE Model Inference]
```

**ë””ë ‰í† ë¦¬ êµ¬ì¡°**
```
myproject/
â”œâ”€â”€ frontend/                  # React ì½”ë“œ
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                   # FastAPI ë°±ì—”ë“œ (í”„ë¡ íŠ¸ <-> RunPod ì—°ê²°)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ eeve-fastapi/              # ğŸ§  RunPod ì „ìš© ëª¨ë¸ ì„œë²„ í´ë” (ìƒˆë¡œ ë§Œë“¦)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ model_server.py
```
ì´ë ‡ê²Œ ê°„ë‹¨í•˜ê²Œ ëª©í‘œì™€ êµ¬í˜„ ê¸°íšì„ ì¡ê³ , ì¤€ë¹„ë˜ì–´ì•¼ ë˜ëŠ” ì‚¬í•­ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.  
ìš°ì„ , ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” [runpod.io](https://docs.runpod.io/serverless/endpoints/overview?utm_source=chatgpt.com) ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ `íšŒì› ê°€ì…ê³¼ API Keyë¥¼ ë°œê¸‰` ë°›ëŠ”ë‹¤.


ì´ì œ ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ë‹¤. 

## 1. Docker ìƒì„±
ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ë„ì»¤ ì´ë¯¸ì§€ë¡œ í•˜ë©´ ì†ŒìŠ¤ ì½”ë“œ ì „ì²´ë¥¼ pod ì¸ìŠ¤í„´ìŠ¤ì— ì˜¬ë¦¬ì§€ ì•Šì•„ë„ í¸í•˜ê²Œ ë°°í¬í•  ìˆ˜ ìˆì–´ì„œ ì‚¬ìš©í–ˆë‹¤.  
`Dockerfile`ì„ ìƒì„±í•œ í›„ ì•„ë˜ì™€ ê°™ì´ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì‘ì„± í•œë‹¤.

### ğŸ‹ Dockerfile
```bash 

FROM python:3.10-slim

# ---- ê¸°ë³¸ ì„¤ì • ----
WORKDIR /app
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# ---- í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ----
RUN apt update && apt install -y git && rm -rf /var/lib/apt/lists/*

# ---- Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ----
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ---- ëª¨ë¸ ì„œë²„ ë³µì‚¬ ----
COPY model_server.py .

# ---- í¬íŠ¸ ì˜¤í”ˆ ----
EXPOSE 8000

# ---- FastAPI ì„œë²„ ìë™ ì‹¤í–‰ ----
CMD ["uvicorn", "model_server:app", "--host", "0.0.0.0", "--port", "8000"]
```


### ğŸ“¦ requirements.txt
```bash
fastapi==0.111.0
uvicorn==0.30.0
transformers==4.44.0
torch==2.3.1
accelerate==0.33.0
safetensors
```

### ğŸ§  model_server.py
```python
from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

app = FastAPI(title="EEVE Model API", version="1.0")

# ---- ëª¨ë¸ ë¡œë“œ ----
model_name = "yanolja/EEVE-Korean-10.8B-v1.0"
print(f"ğŸ”¹ Loading model: {model_name} ...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)
model.eval()
print("âœ… Model loaded successfully")

# ---- ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ----
class GenerateRequest(BaseModel):
    prompt: str
    max_tokens: int = 128
    temperature: float = 0.7

class GenerateResponse(BaseModel):
    text: str

# ---- API ì—”ë“œí¬ì¸íŠ¸ ----
@app.post("/generate", response_model=GenerateResponse)
def generate_text(req: GenerateRequest):
    inputs = tokenizer(req.prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=req.max_tokens,
            temperature=req.temperature,
            do_sample=True
        )
    text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return GenerateResponse(text=text)


@app.get("/")
def root():
    return {"status": "ok", "message": "EEVE model API is running!"}
```

### ğŸ™‹â€â™€ï¸ ë¹Œë“œ ë° í‘¸ì‹œ (ë¡œì»¬ì—ì„œ)

```bash
# docker desktop ì‹¤í–‰ í›„ ë¹Œë“œ ëª…ë ¹ì–´ ì‹¤í–‰
$ docker build -t eeve-fastapi .

# í…ŒìŠ¤íŠ¸ (ë¡œì»¬ì—ì„œ) - ëª¨ë¸ì„ ë°›ì•„ì™€ì•¼ í•´ì„œ ì²˜ìŒì—” ì—„ì²­ ì˜¤ë˜ ê±¸ë¦¼.
$ docker run -p 8000:8000 eeve-fastapi 
```
<br />

## 2. Docker Hub 
> â€œDocker ì´ë¯¸ì§€(ì»¨í…Œì´ë„ˆ íŒ¨í‚¤ì§€)ë¥¼ ì €ì¥í•˜ê³  ê³µìœ í•˜ëŠ” í´ë¼ìš°ë“œ ì €ì¥ì†Œâ€

ìƒì„±ëœ Docker Imageë¥¼ Docker Hubì— ì˜¬ë ¤ì£¼ëŠ” ê³¼ì •ì´ë‹¤. RunPodì€ â€œì„œë²„â€ë¥¼ ë§Œë“¤ì–´ì£¼ê¸´ í•˜ì§€ë§Œ, FastAPI + ëª¨ë¸ ì½”ë“œê°€ ì–´ë–¤ í™˜ê²½ì—ì„œ ëŒì•„ê°€ì•¼ í•˜ëŠ”ì§€ëŠ” RunPodëŠ” ëª¨ë¥´ê¸° ë•Œë¬¸ì— 
- ë¡œì»¬ì—ì„œ Docker ì´ë¯¸ì§€(=FastAPI + EEVE ëª¨ë¸) ë¹Œë“œ.  
- Docker Hubì— ì—…ë¡œë“œ.
- RunPodì´ ê·¸ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ë‹¤ ì‹¤í–‰.

ìˆœìœ¼ë¡œ ì§„í–‰ ëœë‹¤.

### 2-1. ê³„ì • ìƒì„± ë° Docker Image ì—…ë¡œë“œ
[Docker Hub](https://hub.docker.com/repository/docker/focso/eeve-model/general) ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ ê³„ì • ìƒì„± í›„ `Repositories` -> `Create a repository`ë¥¼ í´ë¦­í•˜ì—¬ ìƒì„±í•œë‹¤.

<img src="../../assets/img/content/Python/002/image1.png">


### 2-2. ìƒì„±ëœ Repositoryì— Docker Image Push
```bash
# Docker Hub ë¡œê·¸ì¸
$ docker login
Authenticating with existing credentials... [Username: focso]

i Info â†’ To login with a different account, run 'docker logout' followed by 'docker login'


Login Succeeded

# ë‚´ ê³„ì • ì´ë¦„ìœ¼ë¡œ íƒœê¹…
$ docker tag eeve-fastapi focso/eeve-fastapi:latest

# Docker Hubë¡œ í‘¸ì‹œ (ì—…ë¡œë“œ)
$ docker push focso/eeve-fastapi:latest
The push refers to repository [docker.io/focso/eeve-fastapi]
e17a34e5650c: Pushed
f50935946fb9: Pushed
a09dc670095e: Pushed
e768ee619bf4: Pushed
bb0d17f74bcf: Pushed
d7ecded7702a: Pushed
03b7f5f69b04: Pushed
105196a477ec: Pushed
cfba6d6670cc: Pushed
3599a585f02a: Pushed
latest: digest: sha256:415066ac8122da2ca7c055d0af019e12afd9336f257db93d1f63ba315879f052 size: 856
```


## 3. RunPod ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
ë“œë””ì–´ !! Docker Hubì— ìˆëŠ” Docker Imageë¥¼ pull ë°›ì„ ìˆ˜ ìˆëŠ”  RunPodì—ì„œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ë‹¨ê³„ë‹¤.

### 3-1. ê³„ì • ë° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
[runpod](https://docs.runpod.io/overview)ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ ê³„ì • ìƒì„± í›„ ë¹„ìš© ì„¤ì •ì„ í•´ì¤€ë‹¤.

### 3-2. RunPod ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •
1. RunPod â†’ **Pods â†’ Deploy Pod**
2. ì„ íƒ ì˜µì…˜:
    - **Select an Instance : GPU**
    - **GPU:** ìµœì†Œ 16GB ì´ìƒ ê¶Œì¥
    <img src="../../assets/img/content/Python/002/image2.png">
    - Template: â€œRunpod Pytorch 2.8.0â€
    <img src="../../assets/img/content/Python/002/image3.png">
    - **Image:** `your_dockerhub_username/eeve-fastapi:latest`
    - **Expose HTTP Port:** `8000`
    - **Environment Variables : OLLAMA_HOST=0.0.0.0**
    <img src="../../assets/img/content/Python/002/image4.png">
3. â€œDeploy On-Demandâ€ í´ë¦­



## 4. FastAPI(eeve-fastapi) API í˜¸ì¶œ
ë°°í¬ í›„, RunPodì´ ìë™ìœ¼ë¡œ URLì„ ìƒì„± í•œë‹¤.
```bash
https://<pod-id>-8000.proxy.runpod.net
```

### 4-1. í…ŒìŠ¤íŠ¸
test_request.json íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ vsCodeì—ì„œ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆë‹¤.
<img src="../../assets/img/content/Python/002/image5.png">

```bash
# í…ŒìŠ¤íŠ¸ ë°©ë²• 1
$ curl -X POST https://<pod-id>-8000.proxy.runpod.net/generate -H "Content-Type: application/json" -d @test_request.json

# í…ŒìŠ¤íŠ¸ ë°©ë²• 2
$ curl -X POST https://<pod-id>-8000.proxy.runpod.net/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "ì„œìš¸ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"}'
  
# í…ŒìŠ¤íŠ¸ ë°©ë²• 3
$ curl -i http://localhost:8000/
HTTP/1.1 200 OK
date: Wed, 05 Nov 2025 00:26:48 GMT
server: uvicorn
content-length: 54
content-type: application/json

{"status":"ok","message":"EEVE model API is running!"}

```
ì´ì œ ì´ URLì„ FastAPI ë°±ì—”ë“œë‚˜ React í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ììœ ë¡­ê²Œ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤.ğŸ˜


## 4. FastAPI(backend) API í˜¸ì¶œ
```python
import requests

RUNPOD_URL = "https://<pod-id>-8000.proxy.runpod.net"

def ask_eeve(prompt):
    resp = requests.post(
        f"{RUNPOD_URL}/generate",
        json={"prompt": prompt},
        timeout=60
    )
    data = resp.json()
    return data["text"]

# ì‚¬ìš© ì˜ˆì‹œ
print(ask_eeve("ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€?"))
```

## ë§ˆë¬´ë¦¬
ì‹¤ì œ ì‚¬ìš©í•œ í”„ë¡œì íŠ¸ëŠ”  [EEVE-Game Github](https://github.com/MinJeung-Kim/EEVE-TarotGame)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

ê°œì¸ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ì„œ pod ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì†ì— ê¼½ì„ ìˆ˜ ì—†ì„ ë§Œí¼ ìƒì„±í–ˆë‹¤ ì§€ì› ë‹¤ í•´ë³´ë©´ì„œ,
Runpodì˜ ì‚¬ìš©ë²•ì— ëŒ€í•´ ì¹œìˆ™í•´ ì¡Œë‹¤. FastAPIì™€ Runpodì—ì„œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•œ í›„ ì—”ë“œí¬ì¸íŠ¸ë¡œ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í–ˆë‹¤ê³  í•˜ëŠ” ë¸”ë¡œê·¸ë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ì—†ì–´ì„œ êµ¬í˜„í•˜ëŠ”ë° ì• ë¥¼ ì¢€ ë¨¹ì—ˆì§€ë§Œ, êµ¬í˜„í•˜ê³  ë‚˜ì„œì˜ ë¿Œë“¯í•¨ ë•Œë¬¸ì— ê°œë°œì„ ê³„ì† í•˜ê³  ìˆëŠ”ê²ƒì¼ ì§€ë„..ğŸ˜Š

